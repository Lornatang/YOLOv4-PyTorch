# parameters
number_classes: 20  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,14, 23,27, 37,58]  # P4/16
  - [81,82, 135,169, 344,319]  # P5/32

# Darknet-19 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [16, 3, 1]],  # 0
   [-1, 1, Maxpool, [2, 2]],   # 1-P1/2
   [-1, 1, Conv, [32, 3, 1]],
   [-1, 1, Maxpool, [2, 2]],   # 3-P2/4
   [-1, 1, Conv, [64, 3, 1]],
   [-1, 1, Maxpool, [2, 2]],   # 5-P3/8
   [-1, 1, Conv, [128, 3, 1]],
   [-1, 1, Maxpool, [2, 2]],   # 7-P4/16
   [-1, 1, Conv, [256, 3, 1]],
   [-1, 1, Maxpool, [2, 2]],   # 9-P5/32
   [-1, 1, Conv, [512, 3, 1]],
#  [-1, 1, Maxpool, [2, 1]], fix ` Expected more than 1 value per channel when training, got input size torch.Size([1, 1024, 1, 1])` error
   [-1, 1, Conv, [1024, 3, 1]],  # 11
  ]

# YOLOv3-tiny head
head:
  [[-1, 1, Bottleneck, [512, False]],  # 12

   [-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, "nearest"]],
   [[-1, 8], 1, Concat, [1]],  # concat backbone P4
   [-1, 1, Conv, [256, 1, 1]],  # 16

   [[16, 12], 1, Detect, [number_classes, anchors]],   # Detect(P4, P5)
  ]
